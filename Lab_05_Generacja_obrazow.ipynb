{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<font size=\"5\">\n",
    "\n",
    "Laboratorium z przedmiotu: \\\n",
    "**Głębokie uczenie i analiza obrazów**\n",
    "\n",
    "Ćwiczenie 5: \\\n",
    "**Generacja obrazów z wykorzystaniem GAN**\n",
    "\n",
    "</font>\n",
    "\n",
    "\\\n",
    "Marta Szarmach \\\n",
    "Zakład Telekomunikacji Morskiej \\\n",
    "Wydział Elektryczny \\\n",
    "Uniwersytet Morski w Gdyni\n",
    "\n",
    "10.2023\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "# 1. Wprowadzenie\n",
    "\n",
    "**Generacją obrazów** nazywamy problem tworzenia przez model nowych, nieistniejących wcześniej obrazów. Realizowana jest ona przez modele generatywne, które potrafią na podstawie obrazków z zestawu treningowego $x$ wyznaczać/aproksymować funkcję gęstości prawdopodobieństwa $p(x)$, najczęściej są to modele realizujące uczenie nienadzorowane (nie ma potrzeby dostarczania do modelu etykiet $y$). Generacja obrazów znajduje zastosowanie w takich zadaniach, jak rekonstrukcja obrazów, wspomaganie pracy projektantów (np. odzieży) czy edycja obrazów w grafice komputerowej.\n",
    "\n",
    "Spośród różnych metod generacji obrazów z wykorzystaniem sieci neuronowych, można wymienić:\n",
    "* **VAE** (ang. *Variational AutoEncoder*) - model, który wykorzystuje jedną sieć neuronową (nazywaną enkoderem) do zakodowania reprezentacji obrazów $x$ w przestrzeni ukrytej (ang. *latent space*) $z$, a drugą sieć neuronową (nazywaną dekoderem) do próbkowania $z$ i odtwarzania z tej przestrzeni wygenenerowanych obrazów $\\hat{x}$,\n",
    "* **modele autoregresyjne** - model, który dokonuje predykcji zawartości pikseli na podstawie sąsiadujących z nimi innych pikseli,\n",
    "* **GAN** (ang. *Generative Adversarial Network*) - na którym to modelu skupimy się w ramach dzisiejszego ćwiczenia.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/Argenni/GUiAO_lab/main/rys/09_gan.png'/>\n",
    "\n",
    "<font size=\"1\">Grafika: kdnuggets.com</font>\n",
    "</div>\n",
    "\n",
    "Działanie GANów opiera się na rywalizacji dwóch sieci neuronowych: **generatora**, który dokonując próbkowania z przestrzeni $z$ (szumu), generuje sztuczne dane, oraz **dyskryminatora**, który ma za zadanie dokonać klasyfikacji przesłanych doń danych: czy są sztuczne, czy prawdziwe. Generator $G$ chce przechytrzyć dyskryminator $D$, tworząc coraz bardziej realistyczne obrazki; trwa zatem swoista ,,zabawa w kotka i myszkę'' - im lepszy generator, tym lepszy musi być dyskryminator (i tak w kółko), co ostatecznie prowadzi do powstawania coraz lepszej jakości obrazków. W związku z tym, podczas treningu GANów, wykorzystuje się (w ogólności) poniższą funkcję kosztu:\n",
    "\\begin{equation*}\n",
    "\\min_G \\max_D \\textrm{E}_{x \\sim p(x)}[\\log(D(x))] + \\textrm{E}_{z \\sim p(z)}[\\log(1-D(G(z)))]\n",
    "\\end{equation*} \n",
    "którą należy rozumieć następująco: dyskryminator (uczony zarówno na danych rzeczywistych, jak i wygenerowanych) chce maksymalizować prawdopodobieństwo, że dokona predykcji 1 dla danych rzeczywistych, a 0 dla wygenerowanych, podczas gdy generator (uczony tylko na danych rzeczywistych) chce minimalizować to drugie prawdopodobieństwo. \n",
    "<font size='2'>Do tej funkcji kosztu wrócimy  w odpowiedniej części ćwiczenia.</font>\n",
    "\n",
    "\n",
    "# 2. Cel ćwiczenia\n",
    "\n",
    "**Celem niniejszego ćwiczenia** jest zapoznanie się z budową i działaniem GANów poprzez implementację architektury generatora i dyskryminatora (w formie konwolucyjnej sieci neuronowej o niewielkiej ilości warstw) oraz przeprowadzenie ich treningu z wykorzystaniem biblioteki PyTorch i języka programowania Python.\n",
    "\n",
    "\n",
    "# 3. Stanowisko laboratoryjne\n",
    "\n",
    "Do wykonania niniejszego ćwiczenia niezbędne jest stanowisko laboratoryjne, składające się z komputera klasy PC z zainstalowanym oprogramowaniem:\n",
    "* językiem programowania Python (w wersji 3.8),\n",
    "* IDE obsługującym pliki Jupyter Notebook (np. Visual Studio Code z rozszerzeniem ipykernel).\n",
    "\n",
    "\n",
    "# 4. Przebieg ćwiczenia\n",
    "## Implementacja konwolucyjnego GANu z wykorzystaniem biblioteki PyTorch\n",
    "\n",
    "Na początku wykonaj poniższy fragment kodu, aby zaimportować biblioteki niezbędne do wykonania poniższego ćwiczenia:\n",
    "* **PyTorch** - biblioteka wspomagająca budowanie architektur sieci neuronowych, posiadająca wbudowane moduły odpowiadające różnym warstwom sieci neuronowych, automatyczne obliczanie gradientów (*autograd*) niezbędne do przeprowadzenia treningu sieci neuronowych,\n",
    "* **NumPy** - biblioteka umożliwiająca wykonywanie wysoko zoptymalizowanych obliczeń matematycznych na objektach typu *numpy array* (wielowymiarowych tablic),\n",
    "* **Matplotlib** - biblioteka wspomagająca wizualizację pracy czy analizę danych poprzez wyświetlanie wykresów,\n",
    "* **Scikit-learn** - biblioteka zawierająca gotowe implementacje wielu algorytmów klasycznego uczenia maszynowego, a także zbiory danych czy metryki; tutaj skorzystamy ze zbioru danych z obrazkami przedstawiającymi ręcznie pisane cyfry - `datasets.load_digits`,\n",
    "* **tqdm** - biblioteka wyświetlająca pasek postępu (niezbędna przy korzystaniu z Dataloader, kiedy chcemy automatycznie dzielić zestaw danych treningowych na mini-batche)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install torch==2.0.1\n",
    "! python -m pip install numpy==1.22.3\n",
    "! python -m pip install matplotlib==3.4.2\n",
    "! python -m pip install scikit-learn==0.24.2\n",
    "! python -m pip install tqdm==4.66.1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "# (dla zachowania powtarzalności wyników)\n",
    "np.random.seed(10) \n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie i przygotowanie danych\n",
    "\n",
    "Na początku przygotujmy dane, na których będziemy dziś pracować. Tym razem korzystać będziemy ze zbioru `digits`, zawierającego *num_samples* = 1797 1-kanałowych obrazków o rozmiarze 8x8, przedstawiających odręcznie pisane cyfry. Uruchom kod z poniższej komórki, aby:\n",
    "* wczytać oryginalne dane z zestawu `digits` (`digits.images`) do zmiennej $X$,\n",
    "* dokonać ich normalizacji - wartości w macierzach-obrazkach z zestawu `digits` są z zakresu 0-16, więc aby znormalizować dane, wystarczy podzielić je przez ich największą wartość (16), \n",
    "* przekształcić dane do formatu `torch.tensor`, aby były zrozumiałe dla PyTorcha; jednocześnie wyodrębniając w danych jako drugi wymiar ilość kanałów (w tym przypadku jest to 1): nasze dane wejściowe mają teraz kształt (*num_samples*, *num_channels*, *sample_size*, *sample_size*), gdzie *num_channels* = 1 (dla obrazów RGB byłoby to 3), *sample_size*=8,\n",
    "* przekazać dane do obiektu DataLoader, który będzie w trakcie treningu dzielił je nam na mini-batche o wielkości 64 obrazków,\n",
    "* wyświetlić przykładowe obrazki z danych wejściowych z wykorzystaniem metody `plt.imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- Inicjalizacja ----------------------------\n",
    "# Wczytanie danych\n",
    "digits = load_digits()\n",
    "X = digits.images\n",
    "img_channels = 1 # ilość kanałów w generowanych obrazkach - w datasecie digits równa 1\n",
    "# Przygotowanie danych\n",
    "X = X/16 # normalizacja do zakresu 0-1\n",
    "real = torch.tensor(X.reshape(-1, img_channels, X.shape[1], X.shape[2])) # przekształcenie w 1-kanałowy tensor\n",
    "dataset = torch.utils.data.TensorDataset(real)\n",
    "data_loader = torch.utils.data.DataLoader( # przekazanie do DataLoadera\n",
    "    dataset, batch_size=64,\n",
    "    shuffle=True, drop_last=True)\n",
    "# Graficzna prezentacja danych\n",
    "print(\"Wymiary oryginalnych obrazków: \" + str(real.shape))\n",
    "plt.imshow(np.concatenate((real[0][0],real[100][0],real[200][0], real[300][0]),axis=1), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generacja szumu $z$\n",
    "\n",
    "Na samym początku napiszemy funkcję `generate_noise`, której zadaniem jest losowe tworzenie ,,szumu'', na podstawie którego generowane będą później obrazy. Intuicyjnie, jeśli ,,zastartujemy'' działanie naszego GANu losowymi wartościami w próbce $z^{(i)}$, za każdym razem, kiedy generujemy obraz, możemy wygenerować coś nowego! Niech:\n",
    "* $z$ próbkowane będzie z rozkładu normalnego $\\mathcal{N}(0,1)$ - przyda się tu metoda `torch.randn` ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.randn.html)).\n",
    "* wygenerowany szum jest zapisany w postaci 4-wymiarowego tensora, w którym pierwszy wymiar decyduje o tym, ile próbek (obrazów) chcemy wygenerować (`num_samples`), drugi równy jest wstępnej ilości kanałów (`channels`), a dwa kolejne wynoszą 1 (aby były kompatybilne z późniejszymi konwolucjami - dwa ostatnie wymiary odpowiadają za szerokość i wysokość generowanych obrazków),\n",
    "* wartości zwracanego tensora były w formacie float64 - zadbaj o właściwe ustawienie argumentu `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(num_samples, channels):\n",
    "    \"\"\"\n",
    "    Funkcja dokonująca generacji losowego szumu (z rozkładu normalnego N(0,1)), z którego generowane będą obrazy. \\n\n",
    "    Argumenty: \\n\n",
    "    - num_samples - ilość obrazów, które za pomocą tego szumu chcemgy wygenerować (skalar, int), \\n\n",
    "    - channels - wielkość próbki szumu (skalar, int) \\n\n",
    "    Zwraca: noise - torch tensor zawierający wygenerowany szum, shape=(num_samples, channels, 1, 1)\n",
    "    \"\"\"\n",
    "    # --------- UZUPEŁNIJ KOD -----------------\n",
    "    noise = 0\n",
    "    # ------------------------------------------\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruchom poniższy kod, aby zobaczyć, czy Twoja funkcja rzeczywiście zwraca losowe wartości w tensorze o właściwych rozmiarach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 64 # ilość kanałów, jakie będzie miał wygenerowany szum - nie zmieniaj tej wartości!\n",
    "noise = generate_noise(4, noise_size) # Generacja szumu - takiego, by utworzyć 4 obrazki \n",
    "print(\"Wymiary wygenerowanego szumu: \" + str(noise.shape))\n",
    "print(noise[0:3,0:3,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja generatora\n",
    "\n",
    "W kolejnym kroku zdefiniujemy strukturę pierwszego ze składników naszego GANu, a mianowicie generatora, korzystając z klas dostępnych w bibliotece PyTorch. Tak samo, jak dotychczas, storzymy własną klasę `Generator` (która musi dziedziczyć z klasy `torch.nn.Module`), w której umieścimy dwie metody:\n",
    "* metodę-konstruktor `__init__()` - opisującą budowę naszeg generatora; skorzystamy tu ze znanych już wcześniej warstw `torch.nn.BatchNorm2d`, `torch.nn.ReLU`, czy `torch.nn.Sequential`, ale użyjemy także kilku nowych:\n",
    "    * `torch.nn.ConvTranspose2d` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html)) - realizująca operację odwrotną do konwolucji zwaną **konwolucją transponowaną** bądź też, mniej poprawnie, dekonwolucją; zapewnia upsampling, czyli zwiększanie wymiarów obrazka wraz z każdą warstwą, a wymaga takich argumentów, jak ,,zwykła'' warstwa konwolucyjna: ilość kanałów wejściowych/wyjściowych, wielkość filtra, *padding*, *stride*,\n",
    "    * `torch.nn.Sigmoid` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html)) - realizująca po prostu funkcję aktywacji Sigmoid.\n",
    "* metodę `forward()` - w której określamy przepływ danych pomiędzy warstwami.\n",
    "\n",
    "Uzupełnij zatem poniższy kod! Niech nasz generator składa się z następujących warstw:\n",
    "\n",
    "2 x (`ConvTranspose2d` -> `BatchNorm2d` -> `ReLU`) -> `ConvTranspose2d` -> `Sigmoid`.\n",
    "* Sigmoid na ostatniej warstwie ma zapewnić, że zwracane przez sieć wartości pikseli w generowanych obrazkach też mieszczą się w zakresie 0-1.\n",
    "* Wartości hiperparametrów na warstwach dekonwolucyjnych tutaj zostały predefiniowane przeze mnie:\n",
    "    * podczas pierwszej dekonwolucji, niech wyznaczonych zostanie 128 kanałów, a drugiej - 64, a po trzeciej - 1 (ilość kanałów przechowywana jest w tablicy `num_conv_channels`),\n",
    "    * niech hiperparametr *padding* domyślnie wynosi 0, a *stride* 1 (w razie potrzeby, wartości te przekazywać będziemy konstruktorowi jako argumenty),\n",
    "    * *kernel\\_size* na kolejnych warstwach ustawiłam na sztywno na 2,4,4. \n",
    "\n",
    "<font size='2'>Wyjaśnienie: Po każdej dekonwolucji, wymiary obrazu (szerokość i długość) zmieniają się zgodnie z poniższym wzorem:\n",
    "\\begin{equation*}\n",
    "    sample\\_size_{\\textrm{new}} = (sample\\_size_{\\textrm{original}} -1) \\cdot stride - 2 \\cdot padding  + kernel\\_size\n",
    "\\end{equation*}\n",
    "(jest to przekształcenie, niejako odwrotność wzoru na wymiary obrazu po zwykłej konwolucji). Jeśli wygenerujemy szum o wielkości 16x1x1, to:\n",
    "* po pierwszej dekonwolucji (z *kernel_size* = 2 i *output_channels* = 128) wygenerowane zostaną obrazki o wielkości 128x2x2,\n",
    "* po drugiej dekonwolucji (z *kernel_size* = 4 i *output_channels* = 64) wygenerowane zostaną obrazki o wielkości 64x5x5, \n",
    "* po ostatniej dekonwolucji (z *kernel_size* = 4 i *output_channels* równemu ilości kanałów w obrazkach z `digits`, a zatem 1) wygenerowane zostaną obrazki o wielkości 1x8x8 - takie same, jak w `digits`!</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Model generatora wchodzącego w skład GANu:\n",
    "    (ConvTranspose -> BatchNorm -> ReLU) -> (ConvTranspose -> BatchNorm -> ReLU) -> (ConvTranspose -> Sigmoid)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, output_channels, padding=0, stride=1):\n",
    "        \"\"\"\n",
    "        Definiuje budowę sieci. Argumenty: \\n\n",
    "        - input_channels - ilość kanałów w wejściowych obrazkach (skalar, int), \\n\n",
    "        - output_channel - ilość kanałów w wyjściowych obrazkach (skalar, int), \\n\n",
    "        - padding - (opcjonalnie) ,,grubość'' ramki z zer dodowananej do obrazka (skalar, int, domyślnie 0) \\n\n",
    "        - stride - (opcjonalnie) co ile pikseli obrazka wykonywana jest konwolucja (skalar, int, domyślnie 1).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        num_conv_channels = [128, 64] # ilość kanałów po kolejnych dekonwolucjach\n",
    "        kernel_sizes = [2, 4, 4] # wielkości filtra przy kolejnych dekonwolucjach\n",
    "        # ---------------------- UZUPEŁNIJ KOD -----------------------------------\n",
    "        # Zacznij definiować budowę sieci:\n",
    "        self.first_layer = torch.nn.Sequential(\n",
    "            # ConvTranspose2d\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            # BatchNorm2d\n",
    "            \n",
    "            # Funkcja aktywacji ReLU\n",
    "            \n",
    "            )\n",
    "        self.second_layer = torch.nn.Sequential(\n",
    "            # ConvTranspose2d\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # BatchNorm2d\n",
    "            \n",
    "            # Funkcja aktywacji ReLU\n",
    "            \n",
    "            )\n",
    "        self.third_layer = torch.nn.Sequential(\n",
    "            # ConvTranspose2d\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Sigmoid\n",
    "            \n",
    "        )\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def forward(self, noise):\n",
    "            \"\"\" \n",
    "            Definiuje przepływ danych w sieci. \\n\n",
    "            Argument: noise - dane wejściowe, torch.tensor zawierający szum, z którego generowany ma być obraz, shape=(num_samples, input_channels, 1, 1) \\n\n",
    "            Zwraca: fake - odpowiedź sieci w postaci wygenerowanych obrazów, torch.tensor, shape=(sum_samples, num_channels, sample_size, sample_size)\n",
    "            \"\"\"\n",
    "            # ------------------- UZUPEŁNIJ KOD ----------------\n",
    "\n",
    "\n",
    "            fake = 0\n",
    "            # --------------------------------------------------\n",
    "            return fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujmy wygenerować kilka obrazków z pomocą niewytrenowanego generatora - tylko po to, by sprawdzić, czy wszystko działa i czy wymiary generowanych tensorów się zgadzają. Uruchom więc kod z poniższej komórki, aby utworzyć obiekt stworzonej przez nas klasy `Generator` i wykonać jakiś próbny *forward pass* na wygenerowanym wcześniej szumie `noise`. Wygenerowany tensor powinien mieć wymiary 4x1x8x8, a rysunek... cóż, na razie będzie wyglądał po prostu jak szum!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(noise_size, img_channels) # inicjalizacja generatora\n",
    "gen = gen.double()\n",
    "fake = gen(noise) # generacja obrazków\n",
    "print(\"Wymiary wygenerowanych obrazków: \" + str(fake.shape))\n",
    "fake_np = fake.detach().numpy()\n",
    "plt.imshow(np.concatenate((fake_np[0][0],fake_np[1][0],fake_np[2][0],fake_np[3][0]),axis=1), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacja dyskryminatora\n",
    "\n",
    "Pora na zdefiniowanie budowy kolejnej nieodzownej części GANu - dyskryminatora! Niech nasz dyskryminator składa się z następujących warstw:\n",
    "\n",
    "2 x (`Conv2d` -> `BatchNorm2d` -> `LeakyReLU`) -> `Conv2d` -> `Sigmoid`.\n",
    "\n",
    "Można zauważyć, że jest to architektura bardzo podobna do definiowanego chwilę wcześniej generatora - tyle, że w miejscu warstw dekonwolucyjnych mamy zwykłe konwolucje (nie zależy tu nam na upsamplingu), a w miejscu funkcji aktywacji ReLU - LeakyReLU ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html)) (co ma zapewnić większą stabilność treningu). Wyjściowa funkcja aktywacji Sigmoid ma zapewnić binarną klasyfikację analizowanego obrazka - jako rzeczywistego (1) bądź wygenerowanego sztucznie (0).\n",
    "\n",
    "Spróbuj (na bazie tego, co napisałam w opisie generatora), sam dobrać wielkości filtrów na kolejnych warstwach konwolucyjnych, aby w wyniku konwolucji pierwotnie obrazków o kształcie (*num_samples*, *input_channels*, 8, 8) otrzymać tensor (*num_samples*, 1, 1, 1), który ostatecznie (w wyniku funkcji `torch.squeeze` w instrukcji `return` metody `forward`) zostanie ,,spłaszczony'' do postaci (*num_samples*,)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Model dyskryminatora wchodzącego w skład GANu:\n",
    "    2x (Conv2d -> BatchNorm -> LeakyReLU) -> (Conv2d -> Sigmoid)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, output_channels, padding=0, stride=1):\n",
    "        \"\"\"\n",
    "        Definiuje budowę sieci. Argumenty: \\n\n",
    "        - input_channels - ilość kanałów w wejściowych obrazkach (skalar, int), \\n\n",
    "        - output_channel - ilość kanałów w wyjściowych obrazkach (skalar, int), \\n\n",
    "        - padding - ,,grubość'' ramki z zer dodowananej do obrazka (skalar, int, domyślnie 0), \\n\n",
    "        - stride - co ile pikseli obrazka wykonywana jest konwolucja (skalar, int, domyślnie 1).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        num_conv_channels = [128, 64] # ilość kanałów po kolejnych konwolucjach\n",
    "        # ---------------------- UZUPEŁNIJ KOD -----------------------------------\n",
    "        kernel_sizes = 0 # wielkości filtra przy kolejnych konwolucjach\n",
    "        \n",
    "        # Zacznij definiować budowę sieci:\n",
    "        self.first_layer = torch.nn.Sequential(\n",
    "            # Conv2d\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # BatchNorm2d\n",
    "            \n",
    "            # Funkcja aktywacji LeakyReLU\n",
    "             \n",
    "            )\n",
    "        self.second_layer = torch.nn.Sequential(\n",
    "            # Conv2d\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # BatchNorm2d\n",
    "            \n",
    "            # Funkcja aktywacji LeakyReLU\n",
    "             \n",
    "            )\n",
    "        self.third_layer = torch.nn.Sequential(\n",
    "            # Conv2d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Sigmoid\n",
    "            \n",
    "        )\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def forward(self, images):\n",
    "            \"\"\" \n",
    "            Definiuje przepływ danych w sieci. \\n\n",
    "            Argument: images - dane wejściowe, torch.tensor zawierający obrazki do analizy, shape=(sum_samples, num_channels, sample_size, sample_size) \\n\n",
    "            Zwraca: out - odpowiedź sieci: 0 (obrazek fałszywy) - 1 (obrazek prawdziwy), torch.tensor, shape=(sum_samples,)\n",
    "            \"\"\"\n",
    "            # ------------------- UZUPEŁNIJ KOD ----------------\n",
    "            \n",
    "            out = 0\n",
    "            # --------------------------------------------------\n",
    "            return torch.squeeze(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kod z poniższej komórki pozwoli nam sprawdzić poprawność implementacji naszego dyskryminatora. Po utworzeniu obiektu klasy `Discriminator`, sprawdzimy, jak klasyfikuje on kilka wygenerowanych wcześniej obrazków (przechowywanych w zmiennej `fake`), a także kilka rzeczywistych, ze zbioru `digits` (przechowywanych jako `real`). Ponownie, nie spodziewajmy się spektakularnych wyników - nasz dyskryminator nie został jeszcze wcale wytrenowany (sprawdzamy jedynie poprawność kodu), jego decyzje są póki co zupełnie losowe (dokładność na poziomie 50%.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(img_channels, 1) # inicjalizacja dyksryminatora\n",
    "disc = disc.double()\n",
    "pred = np.round(disc(fake).detach().numpy()) # predykcje dyskryminatora na danych (wcześniej) wygenerowanych \n",
    "accuracy = np.mean(pred == np.zeros_like(pred)) * 100\n",
    "print(\"Dokładność zainicjowanego dyskryminatora na wygenerowanych obrazkach: \" + str(accuracy) + \"%\")\n",
    "real_batch = real[0:4,:,:,:]\n",
    "pred = np.round(disc(real_batch).detach().numpy()) # predykcje dyskryminatora na danych rzeczywistych \n",
    "accuracy = np.mean(pred == np.ones_like(pred)) * 100\n",
    "print(\"Dokładność zainicjowanego dyskryminatora na rzeczywistych obrazkach: \" + str(accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trening\n",
    "\n",
    "Pozostała ostatnia, natrudniejsza w tym ćwiczeniu część: napiszmy funkcję `train_GAN()`, w której przeprowadzimy trening naszgo GANu. \n",
    "\n",
    "* Wykorzystajmy, podobnie, jak poprzednio, algorytm optymalizacji Adam - tym razem jednak będziemy musieli utworzyć nie jeden, a dwa obiekty związane z tym algorytmem - jeden dokonujący optymalizacji parametrów generatora (tworzymy obiekt klasy `Generator` o nazwie `gen`), a drugi - dyskryminatora (tworzymy obiekt klasy `Discriminator` o nazwie `disc`). Hiperparametry niezbędne do działania tego algorytmu mamy podane przeze mnie:\n",
    "    * stała uczenia $\\alpha$ (zmienna i argument `lr`) będzie miała wartość 0,002,\n",
    "    * współczynniki $\\Beta_1$ i $\\Beta_2$ (zmienna i argument `betas`) będą miały wartość odpowiednio 0,999 i 0.5,\n",
    "    * nie używamy regularyzacji (nic nie przekazujemy jako argument `weight_decay`).\n",
    "* Rzeczywistych obrazków (w zmiennej `real[0]`) dostarcza nam w kolejnych iteracjach obiekt klasy `DataLoader`.\n",
    "* Nie wykorzystamy żadnych gotowych funkcji obliczających wartość kosztu - musimy napisać własną! Do treningu GANów, wykorzystuje się następująco opisanymi funkcjami kosztu:\n",
    "    * dyskryminator chce minimalizować szansę na to, że obrazki podsyłane mu przez generator zostaną przez niego ocenione jako prawdziwe, a jednocześnie maksymalizować szanse na to, że ,,przepuści'' rzeczywiste obrazki - musimy więc optymalizować wyrażenie:\n",
    "    \\begin{equation*}\n",
    "        J_d = -\\frac{1}{m} [\\log(D(x^{(i)})) + \\log(1-D(G(z^{(i)}))) ]\n",
    "    \\end{equation*}\n",
    "    * generator chce maksymalizować szanse na to, że dyskryminator oceni wygenerowane przez niego obrazki jako prawdziwe - należy więc optymalizować wyrażenie: \n",
    "    \\begin{equation*}\n",
    "        J_g = -\\frac{1}{m} \\log(D(G(z^{(i)})))\n",
    "    \\end{equation*}\n",
    "    W powyższych wyrażeniach:\n",
    "    * $m$ oznacza ilość obrazków w mini-batchu (przechowywana jako pole `batch_size` obiektu klasy `DataLoader`),\n",
    "    * $G(z^{(i)})$ to sztuczny obrazek wygenerowany przez generator z próbki szumu $z^{(i)}$\n",
    "    * $D(x^{(i)})$ to odpowiedź dyskryminatora na $i$-tą próbkę rzeczywistych danych, a $D(G(z^{(i)}))$ - jego odpowiedź na sztuczny obrazek.\n",
    "* Pozostałe elementy są podobne jak w poprzednich ćwiczeniach: należy przestawić sieci w tryb treningu, przeprowadzamy *forward pass* (tutaj musimy najpierw wygenerować `noise` - próbki szumu $z^{(i)}$ z pomocą funkcji `generate_noise`, następnie obliczyć $G(z^{(i)})$, wywołując `gen` z tą próbką, otrzymując w tej sposób sztuczne obrazki `fake`, a potem możemy obliczyć `pred_fake` $D(G(z^{(i)}))$, tj. dokonać ich oceny przez dyskryminator, wywołując `disc`), obliczamy wartości funkcji kosztu, zerujemy gradienty (`.zero_grad()`), wykonujemy propagację wsteczną ( `.backward()`) oraz wywołujemy jedną iterację algorytmu optymalizacji (`.step()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(data_loader, img_channels, noise_size):\n",
    "    \"\"\"\n",
    "    Wykonaj trening GANu na zadanych danych wejściowych i z określonymi ilościami kanałów. \\n\n",
    "    Argumenty: \\n\n",
    "    - data_loader - obiekt klasy torch.utils.data.DataLoader, zawierający dane treningowe i dzielący je na mini-batche, \\n\n",
    "    - img_channels - ilość kanałów w docelowych generowanych obrazkach (skalar, int), \\n\n",
    "    - noise_size - wielkość próbki szumu (niezbędny do uruchomienia generate_noise), (skalar, int). \\n\n",
    "    Zwraca: gen - wytrenowana sieć neuronowa zdefiniowanej wcześniej klasy Generator.\n",
    "    \"\"\"\n",
    "    # Niezbędne zmienne\n",
    "    step = 0 # inicjalizacja zmiennej zliczającej ilość dokonanych aktualizacji parametrów\n",
    "    lr = 0.0002 # stała uczenia (wymagane przez Adam)\n",
    "    betas = (0.5, 0.999) # bety dla Adam\n",
    "    gen = Generator(noise_size, img_channels) # Inicjalizacja generatora\n",
    "    gen = gen.double()\n",
    "    disc = Discriminator(img_channels, 1) # Inicjalizacja dyksryminatora\n",
    "    disc = disc.double()\n",
    "    # ---------------------------- UZUPEŁNIJ KOD -------------------------------------------------------------------\n",
    "    # Utwórz obiekty związane z metodą optymalizacji - Adam - dla generatora i dyskryminatora\n",
    "    optimizer_gen = 0\n",
    "    optimizer_disc = 0\n",
    "    # Przełącz obie sieci neuronowe w tryb treningu\n",
    "\n",
    "\n",
    "    for i in range(200):\n",
    "        for real in tqdm.tqdm(data_loader):\n",
    "            step = step + 1\n",
    "            # Wygeneruj szum, który posłuży do generacji obrazów - tyle próbek, ile ma zestaw rzeczywistych obrazków\n",
    "            noise = 0\n",
    "            # Wykonaj forward pass na generatorze - wygeneruj obrazy na podstawie wcześniejszego noise\n",
    "            fake = 0       \n",
    "\n",
    "            # Optymalizacja dyskryminatora\n",
    "            # a) Oblicz predykcje na obrazach wygenerowanych\n",
    "            # (zrób .detach() na pred_fake, aby generator nie był zmieniany)\n",
    "            pred_fake = 0\n",
    "            # b) Oblicz predykcje na obrazach rzeczywistych\n",
    "            pred_real = 0\n",
    "            # c) Oblicz koszt dyskryminatora\n",
    "            loss_disc = 0\n",
    "            # f) Wyzeruj gradienty dla dyskryminatora\n",
    "            \n",
    "            # d) Wykonaj propagację wsteczną kosztu - uwaga, należy wymusić zachowanie obliczeń, przekazując retain_graph=True\n",
    "            \n",
    "            # e) Wykonaj 1 iterację algorytmu optymalizacji dla dyskryminatora\n",
    "            \n",
    "\n",
    "            # Optymalizacja generatora\n",
    "            # a) Oblicz koszt na obrazach wygenerowanych\n",
    "            pred_fake = 0\n",
    "            loss_gen = 0\n",
    "            # d) Wyzeruj gradienty dla dyskryminatora\n",
    "            \n",
    "            # b) Wykonaj propagację wsteczną kosztu\n",
    "            \n",
    "            # c) Wykonaj 1 iterację algorytmu optymalizacji dla dyskryminatora\n",
    "            \n",
    "            # ----------------------------------------------------------------------------------------------------\n",
    "            if step%1000==0: # Co pewien czas sprawdź jakość treningu\n",
    "                print(\"Iteracja \" + str(step) + \":\")\n",
    "                print(\" Koszt generatora: \" + str(loss_gen))\n",
    "                print(\" Koszt dyskryminatora: \" + str(loss_disc))\n",
    "                fake = fake.detach().numpy()\n",
    "                plt.figure()\n",
    "                plt.imshow(np.concatenate((fake[0][0],fake[1][0],fake[2][0], fake[3][0]),axis=1), cmap='gray')\n",
    "                plt.show(block=False)\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonajmy zatem treningu naszego GANu! Aby mieć podgląd na to, jak przebiega trening, co pewien czas wyświetlane będą wartości kosztu zarówno dla generatora, jak i dyskryminatora, a także próbka generowanych na ten moment obrazków. Im dłuższy trening, tym bardziej obrazki powinny przypominać ręcznie pisane cyferki, jak w zestawie `digits`, a nie szum. \n",
    "\n",
    "Podziwiaj obrazki otrzymywane pod sam koniec treningu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Trening ------------------------\n",
    "gen = train_GAN(data_loader, img_channels, noise_size)\n",
    "# Prezentacja wygenerowanych obrazków po treningu\n",
    "fake = gen(noise).detach().numpy()\n",
    "plt.imshow(np.concatenate((fake[0][0],fake[1][0],fake[2][0], fake[3][0]),axis=1), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pytania kontrolne\n",
    "1. Opisz rolę generatora jako składnika GANów.\n",
    "2. Opisz rolę dyskryminatora jako składnika GANów.\n",
    "3. Jak pokrótce wygląda trening GANów?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
