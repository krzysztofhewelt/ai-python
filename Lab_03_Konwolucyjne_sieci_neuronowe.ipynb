{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<font size=\"5\">\n",
    "\n",
    "Laboratorium z przedmiotu: \\\n",
    "**Głębokie uczenie i analiza obrazów**\n",
    "\n",
    "Ćwiczenie 3: \\\n",
    "**Konwolucyjne sieci neuronowe**\n",
    "\n",
    "</font>\n",
    "\n",
    "\\\n",
    "Marta Szarmach \\\n",
    "Zakład Telekomunikacji Morskiej \\\n",
    "Wydział Elektryczny \\\n",
    "Uniwersytet Morski w Gdyni\n",
    "\n",
    "09.2023\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "# 1. Wprowadzenie\n",
    "\n",
    "**Konwolucyjne sieci neuronowe** (ang. *convolutional neural networks*, CNN) to sieci, których działanie opiera się na konwolucji. W skrócie, sygnał dostarczony do sieci neuronowej (np. zdjęcie) analizowany jest fragment po fragmencie poprzez wykonanie konwolucji (wymnożenia i zsumowania) tegoż fragmentu z pewnym **filtrem** (ang. *kernel*). Zadaniem filtra jest (poprzez konwolucję) rozpoznanie w analizowanym sygnale pewnych cech (np. krawędzi), a na późniejszych etapie nawet pewnych obiektów. To właśnie na zawartość filtra składają się parametry sieci konwolucyjnej, wyznaczane w ramach jej treningu. \n",
    "\n",
    "Z racji swojej budowy i działania, konwolucyjne sieci neuronowe znalazły szerokie zastosowanie w analizie obrazów. Obrazy są najczęściej przedstawiane w formie 3-kanałowych macierzy (RGB), a następnie poddawane są konwolucji z filtrami, na którą wzór można zapisać tak:\n",
    "\\begin{equation*}\n",
    "    (A * H)[m,n] = \\sum_j \\sum_k H[j,k] \\cdot A[m-j,n-k]\n",
    "\\end{equation*}\n",
    "Każdy filtr ma za zadanie wykryć pewną konkretną cechę/zawartość analizowanego fragmentu obrazu. Zaczyna się zazwyczaj od odnajdywania prostych elementów, takich, jak krawędzie, a następnie, na kolejnych warstwach, sieć jest w stanie wykrywać coraz bardziej złożone kształty i obiekty. Zazwyczaj z każdą kolejną warstwą konwolucyjną zwiększa się ilość kanałów sygnału (tj. wykrywa się więcej kształtów).\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src='https://i0.wp.com/developersbreach.com/wp-content/uploads/2020/08/cnn_banner.png?fit=1400%2C658&ssl=1'/>\n",
    "\n",
    "<font size=\"1\">Grafika: developersbreach.com</font>\n",
    "</div>\n",
    "\n",
    "Typowa budowa sieci konwolucyjnej przedstawiona jest na powyższym rysunku. Zazwyczaj sieci te buduje się z kilku występującycj po sobie bloków, złożonych z warstwy konwolucyjnej (wykonującej właściwą konwolucję), warstwy aktywacyjnej (np. ReLU) oraz innych, takich jak *dropout* czy *BatchNorm*. Na końcu sieci znajduje się najczęściej warstwa Flatten, która sprowadza dane dlań wejściowe do postaci 1-wymiarowego tensora, a za nią dane te przekształcane są przez jedną bądź kilka warstw liniowych. Na końcu sieci występuje warstwa przeprowadzająca ostateczną predykcję - w zależności od rozwiązywanego problemu, może to być Sigmoid, Softmax, itp.\n",
    "\n",
    "Pomiędzy blokami konwolucyjnymi możemy użyć także dodatkowej warstwy, zwanej *pooling layer*, która ma na celu zmiejszenie wymiaru ,,obrazu'' przekazywanego do następnej warstwy. Mamy fo wyboru:\n",
    "* *max pooling* - grupa pikseli zastępowana jest jednym, o wartości największej z grupy,\n",
    "* *average pooling* - grupa pikseli zastępowana jest jednym, o wartości średniej całej grupy.\n",
    "\n",
    "Hiperparametrami regulującymi działanie konwolucyjnych sieci neuronowych, które nie występowały w ,,zwykłych'' sieciach neuronowych (opartych na warstwach liniowych), są:\n",
    "* *kernel_size* - wielkość filtra,\n",
    "* *padding* - określa, jak „szeroka” ma być dodana (na dowolnej warstwie) do obrazu ramka z zer, co ma przeciwdziałać nadmiernemu zmiejszaniu się wymiarów obrazu wraz z kolejnymi konwolucjami, a także umożliwić dokładniejszą analizę brzegów obrazu,\n",
    "* *stride* - określa, za ile pikseli filtr wykona następną konwolucję.\n",
    "\n",
    "\n",
    "\n",
    "# 2. Cel ćwiczenia\n",
    "\n",
    "**Celem niniejszego ćwiczenia** jest zapoznanie się z budową i działaniem konwolucyjnych sieci neuronowych poprzez:\n",
    "* implementacji architektury pewnej konwolucyjnej sieci neuronowej o niewielkiej ilości warstw z wykorzystaniem biblioteki PyTorch i języka programowania Python,\n",
    "* skorzystanie z implementacji gotowej sieci konwolucyjnej, realizującej klasyfikację obrazów - AlexNet.\n",
    "\n",
    "\n",
    "# 3. Stanowisko laboratoryjne\n",
    "\n",
    "Do wykonania niniejszego ćwiczenia niezbędne jest stanowisko laboratoryjne, składające się z komputera klasy PC z zainstalowanym oprogramowaniem:\n",
    "* językiem programowania Python (w wersji 3.8),\n",
    "* IDE obsługującym pliki Jupyter Notebook (np. Visual Studio Code z rozszerzeniem ipykernel).\n",
    "\n",
    "\n",
    "# 4. Przebieg ćwiczenia\n",
    "## 4.1. Implementacja konwolucyjnej sieci neuronowej z wykorzystaniem biblioteki PyTorch\n",
    "\n",
    "Na początku wykonaj poniższy fragment kodu, aby zaimportować biblioteki niezbędne do wykonania poniższego ćwiczenia:\n",
    "* **PyTorch** - biblioteka wspomagająca budowanie architektur sieci neuronowych, posiadająca wbudowane moduły odpowiadające różnym warstwom sieci neuronowych, automatyczne obliczanie gradientów (*autograd*) niezbędne do przeprowadzenia treningu sieci neuronowych,\n",
    "* **NumPy** - biblioteka umożliwiająca wykonywanie wysoko zoptymalizowanych obliczeń matematycznych na objektach typu *numpy array* (wielowymiarowych tablic),\n",
    "* **Matplotlib** - biblioteka wspomagająca wizualizację pracy czy analizę danych poprzez wyświetlanie wykresów,\n",
    "* **Scikit-learn** - biblioteka zawierająca gotowe implementacje wielu algorytmów klasycznego uczenia maszynowego, a także zbiory danych czy metryki; tutaj skorzystamy ze zbioru danych MNIST - `datasets.load_digits` oraz metody `model_selection.train_test_split` służącej do podziału danych na zestaw treningowy i testowy,\n",
    "* **Optuna** - biblioteka zawierająca narzędzia automatyzujące optymalizację danej funkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:02:20.680780100Z",
     "start_time": "2023-11-01T18:02:20.637592300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x224b67e8b70>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! python -m pip install torch==2.0.1\n",
    "# ! python -m pip install numpy==1.22.3\n",
    "# ! python -m pip install scikit-learn==0.24.2\n",
    "# ! python -m pip install matplotlib==3.4.2\n",
    "# ! python -m pip install optuna\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "# (dla zachowania powtarzalności wyników)\n",
    "np.random.seed(10) \n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie i przygotowanie danych\n",
    "\n",
    "Na początku przygotujmy dane, na których będziemy dziś pracować. Tym razem korzystać będziemy ze zbioru MNIST, zawierającego *num_samples* = 1797 obrazków o rozmiarze 8x8, przedstawiających odręcznie pisane cyfry. Uruchom kod z poniższej komórki, aby:\n",
    "* wczytać oryginalne dane z zestawu MNIST (`digits`) do zmiennej $X$ i ich etykiety do zmiennej $y$,\n",
    "* obliczyć (z wykorzystaniem metody `numpy.unique`) w automatyczny sposób ilość klas występujących w naszym zbiorze danych (tj. ilość unikalnych wartości w etykietach) - wiemy, że powinno ich być 10, tyle, ile cyfr,\n",
    "* z pomocą `train_test_split` wydzielić 70% obrazków jako zestaw treningowy $Xtrain$, a pozostałą część danych po równo podzielić na zestaw walidacyjny $Xval$ i testowy $Xtest$ (po 15%),\n",
    "* przygotować etykiety tak, aby współpracowały z funkcją kosztu `CrossEntropyLoss`, którą zastosujemy przy treningu naszej sieci - odpowiedź od każdego neuronu zbierana będzie w osobnej kolumnie tablicy, dlatego nasze etykiety w formacie (*num_samples*,), zawierające wartości 0,1,...9 przekształcimy za pomocą one-hot-encodingu do postaci (*num_samples*, *num_classes*), np. 2 -> [0,0,1]\n",
    "* ostatecznie, dane i przekształcone etykiety, które będą przekazywane sieci neuronowej, przekształcić do formatu `torch.tensor`, aby były zrozumiałe dla PyTorcha; jednocześnie wyodrębniając w danych jako drugi wymiar ilość kanałów (w tym przypadku jest to 1): nasze dane wejściowe mają teraz kształt (*num_samples*, *num_channels*, *sample_size*, *sample_size*), gdzie *num_channels* = 1 (dla obrazów RGB byłoby to 3), *sample_size*=8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:02:20.753273Z",
     "start_time": "2023-11-01T18:02:20.645100700Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------- Inicjalizacja ----------------------------\n",
    "# Wczytanie danych\n",
    "digits = load_digits()\n",
    "X = digits.images\n",
    "y = digits.target\n",
    "num_classes = (np.unique(y)).shape[0]\n",
    "# Podziel dane na zestaw treningowy (70%), walidacyjny (15%) i testowy (15%) z wykorzystaniem metody train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y,train_size=0.6)\n",
    "Xval, Xtest, yval, ytest = train_test_split(Xtest,ytest,train_size=0.5)\n",
    "# Dokonaj one-hot-encodingu etykiet z zestawu treningowego i walidacyjnego\n",
    "ytrain_ohe = np.identity(num_classes)[ytrain]\n",
    "yval_ohe = np.identity(num_classes)[yval]\n",
    "# Przekonwertuj dane wejściowe na tensory, by mogłby być obsługiwane przez PyTorch\n",
    "# i jednocześnie wydziel wymiar 1 jako ilość kanałów\n",
    "Xtrain = torch.tensor(Xtrain.reshape(-1, 1, Xtrain.shape[1], Xtrain.shape[2]))\n",
    "ytrain_ohe = torch.tensor(ytrain_ohe) \n",
    "Xval = torch.tensor(Xval.reshape(-1, 1, Xval.shape[1], Xval.shape[2])) \n",
    "yval_ohe = torch.tensor(yval_ohe)\n",
    "Xtest = torch.tensor(Xtest.reshape(-1, 1, Xtest.shape[1], Xtest.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Określenie struktury naszej sieci neuronowej\n",
    "\n",
    "W kolejnym kroku zdefiniujemy strukturę naszej konwolucyjnej  sieci neuronowej, korzystając z klas dostępnych w bibliotece PyTorch! Tak samo, jak ostatnio, zrobimy to w naszej własnej klasie - nazwijmy ją `ConvNet` - która musi dziedziczyć z klasy `torch.nn.Module`, w której umieścimy dwie metody:\n",
    "* metodę-konstruktor `__init__()` - opisującą budowę sieci; skorzystamy tu ze znanych już wcześniej warstw `torch.nn.Linear`, `torch.nn.ReLU`, `torch.nn.Dropout`, `torch.nn.Softmax` czy `torch.nn.Sequential`, ale użyjemy także kilku nowych, charakterystycznych dla konwolucyjnych sieci neuronowych:\n",
    "    * `torch.nn.Conv2d` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)) - realizująca właściwą konwolucję pomiędzy filtrami a fragmentami obrazów; wymaga takich argumentów, jak: ilość kanałów wejściowych/wyjściowych, wielkość filtra, *padding*, *stride*,\n",
    "    * `torch.nn.BatchNorm` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)) i ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)) - realizująca normalizację wsadową, zarówno na obrazach (2d), jak i na 1-wymiarowych tensorach (1d),\n",
    "    * `torch.nn.Flatten` - ([TUTAJ](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)) - realizująca ,,wypłaszczenie'' wejściowego sygnału 2d do postaci 1-wymiarowego tensora.\n",
    "* metodę `forward()` - w której określamy przepływ danych pomiędzy warstwami.\n",
    "\n",
    "Uzupełnij zatem poniższy kod! Oto założenia:\n",
    "* Niech nasza sieć neuronowa składa się z następujących warstw:\n",
    "\n",
    "2 x (`Conv2d` -> `BatchNorm2d` -> `Dropout` -> `ReLU`) -> `Flatten` -> `Linear` -> `BatchNorm1d` -> `Dropout` -> `Softmax`.\n",
    "* Podczas pierwszej konwolucji, niech wyznaczonych zostanie 16 kanałów, a po drugiej - 32 (ilość kanałów przechowywana jest w tablicy `num_conv_channels`).\n",
    "* Prawdopodobieństwo odrzucenia neuronu przez `dropout` niech wynosi 0,25.\n",
    "\n",
    "Wskazówki:\n",
    "* Po każdej konwolucji, wymiary obrazu (szerokość i długość) zmieniają się zgodnie z poniższym wzorem:\n",
    "\\begin{equation*}\n",
    "    sample\\_size_{\\textrm{new}} = \\frac{sample\\_size_{\\textrm{original}} + 2 \\cdot padding - kernel\\_size}{stride} + 1 \n",
    "\\end{equation*}\n",
    "* Zastanów się, jak długi tensor zwróci nam warstwa ```Flatten``` (będzie Ci to potrzebne do właściwej inicjalizacji warstwy ```Linear```) - do policzenia tego, na pewno będziesz potrzebować wymiaru obrazka po ostatniej konwolucji, a także ilości kanałów po tejże konwolucji!\n",
    "* `BatchNorm2d` jako argument  `num_features` wymaga ilości kanałów w analizowanych przezeń danych, natomiast `BatchNorm1d` - ilość neuronów z ostatniej warstwy Linear.\n",
    "* Wszystkie niezbędne dane przekazywać będziemy konstruktorowi jako argumenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:16:32.398643900Z",
     "start_time": "2023-11-01T18:16:32.393120300Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Model konwolucyjnej sieci neuronowej:\n",
    "    (Conv -> BatchNorm -> Dropout -> ReLU) -> (Conv -> BatchNorm -> Dropout -> ReLU) -> (Flatten -> Linear -> BatchNorm -> Dropout -> Softmax)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_channels, sample_size, output_layer_size, kernel_size, padding, stride):\n",
    "        \"\"\"\n",
    "        Definiuje budowę sieci. Argumenty: \\n\n",
    "        - input_channels - ilość kanałów w wejściowych obrazkach (skalar, int)\n",
    "        - sample_size - długość/szerokość wejściowego obrazka (skalar, int)\n",
    "        - output_layer_size - ilość neuronów na ostatniej warstwie (skalar, int)\n",
    "        - kernel_size - wielkość filtra do konwolucji (skalar, int)\n",
    "        - padding - ,,grubość'' ramki z zer dodowananej do obrazka (skalar, int)\n",
    "        - stride - co ile pikseli obrazka wykonywana jest konwolucja (skalar, int)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        num_conv_channels = [16, 32] # Do dowolnej modyfikacji - ilość kanałów po kolejnych konwolucjach\n",
    "        # ---------------------- UZUPEŁNIJ KOD -----------------------------------\n",
    "        # Oblicz rozmiary obrazków po pierwszej konwolucji\n",
    "        size1 = ((sample_size + 2 * padding - kernel_size) / stride) + 1\n",
    "        # Oblicz rozmiary obrazków po drugiej konwolucji\n",
    "        size2 = int(((size1 + 2 * padding - kernel_size) / stride) + 1)\n",
    "        # Zacznij definiować budowę sieci:\n",
    "        self.first_layer = torch.nn.Sequential(\n",
    "            # Warstwa konwolucyjna\n",
    "            torch.nn.Conv2d(\n",
    "                 in_channels=input_channels,\n",
    "                 out_channels=num_conv_channels[0],\n",
    "                 kernel_size=kernel_size,\n",
    "                 padding=padding,\n",
    "                 stride=stride\n",
    "            ),\n",
    "            # BatchNorm2d\n",
    "            torch.nn.BatchNorm2d(num_features=num_conv_channels[0]),\n",
    "            # Dropout (niech neuron zostanie usunięty z prawdopodobieństwem 0.25)\n",
    "            torch.nn.Dropout(0.25),\n",
    "            # Funkcja aktywacji ReLU\n",
    "            torch.nn.ReLU() \n",
    "        )\n",
    "        self.second_layer = torch.nn.Sequential(\n",
    "            # Warstwa konwolucyjna\n",
    "            torch.nn.Conv2d(\n",
    "                 in_channels=num_conv_channels[0],\n",
    "                 out_channels=num_conv_channels[1],\n",
    "                 kernel_size=kernel_size,\n",
    "                 padding=padding,\n",
    "                 stride=stride\n",
    "            ),\n",
    "            # BatchNorm2d\n",
    "            torch.nn.BatchNorm2d(num_features=num_conv_channels[1]),\n",
    "            # Dropout (niech neuron zostanie usunięty z prawdopodobieństwem 0.25)\n",
    "            torch.nn.Dropout(0.25),\n",
    "            # Funkcja aktywacji ReLU\n",
    "            torch.nn.ReLU() \n",
    "        )\n",
    "        self.third_layer = torch.nn.Sequential(\n",
    "            # Flatten\n",
    "            torch.nn.Flatten(),\n",
    "            # Linear\n",
    "            torch.nn.Linear(\n",
    "                 in_features=size2 * size2 * 32,\n",
    "                 out_features=output_layer_size\n",
    "            ),\n",
    "            # BatchNorm1d\n",
    "            torch.nn.BatchNorm1d(num_features=output_layer_size),\n",
    "            # Dropout\n",
    "            torch.nn.Dropout(0.25),\n",
    "            # Softmax\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "        # ---------------------------------------------------------------------\n",
    "\n",
    "    def forward(self, X):\n",
    "            \"\"\" \n",
    "            Definiuje przepływ danych w sieci. \\n\n",
    "            Argument: X - dane wejściowe, obrazki w postaci torch.tensor, shape=(num_samples, input_channels, sample_size, sample_size) \\n\n",
    "            Zwraca: X - odpowiedź sieci w postaci prawdopodobieństw, torch.tensor, shape=(sum_samples, num_classes)\n",
    "            \"\"\"\n",
    "            # ------------------- UZUPEŁNIJ KOD ----------------\n",
    "            X = self.first_layer(X)\n",
    "            X = self.second_layer(X)\n",
    "            X = self.third_layer(X)\n",
    "            # --------------------------------------------------\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujmy utworzyć obiekt stworzonej przez nas klasy ConvNet i wykonać jakiś próbny *forward pass* na danych walidacyjnych, aby przekonać się, czy budowa naszej sieci jest poprawna (przynajmniej pod kątem składnowym i numerycznym, tj. czy zgadzają się wymiary tensorów przekazywanych pomiędzy warstwami). Uruchom więc kod z poniższej komórki. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:16:33.633114500Z",
     "start_time": "2023-11-01T18:16:33.620095800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowe predykcje modelu na danych walidacyjnych: tensor([[0.1337, 0.1067, 0.0210, 0.1159, 0.0591, 0.0370, 0.1159, 0.1397, 0.1550,\n",
      "         0.1159],\n",
      "        [0.0521, 0.0521, 0.0728, 0.0962, 0.0058, 0.5199, 0.0042, 0.0101, 0.0042,\n",
      "         0.1825],\n",
      "        [0.1179, 0.0907, 0.0069, 0.0938, 0.0440, 0.0440, 0.0527, 0.1734, 0.3579,\n",
      "         0.0186]], dtype=torch.float64, grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "cnn = ConvNet(\n",
    "    input_channels=1,\n",
    "    sample_size=Xval.shape[2],\n",
    "    output_layer_size=num_classes,\n",
    "    kernel_size=3,\n",
    "    padding=0,\n",
    "    stride=1)\n",
    "cnn = cnn.double()\n",
    "pred = cnn(Xval)\n",
    "print(\"Przykładowe predykcje modelu na danych walidacyjnych: \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbieramy odpowiedzi od każdego wyjściowego neuronu, a każda oznacza prawdopodobieństwo przynależności badanego obrazka do odpowiedniej klasy. Pamiętaj, że nie ma po co przywiązywać się do predykcji otrzymanych na tym etapie - sieć jeszcze nie została niczego nauczona! \n",
    "\n",
    "\n",
    "### Trening sieci neuronowej\n",
    "\n",
    "Napiszmy w takim razie funkcję `train_cnn()`, w której przeprowadzimy trening naszej konwolucyjnej sieci neuronowej. Podobnie, jak poprzednio, wykorzystajmy algorytm optymalizacji Adam (który, jak pamiętamy, potrzebuje odniesienia do parametrów, które ma optymalizować (argument `params` - przekażmy wynik metody `parameters()` na obiekcie naszej klasy ConvNet), stałej uczenia $\\alpha$ (argument `lr` - przekażmy na stałe wartość 0,005), a także stałej regularyzacji $\\lambda$ (argument `weight_decay` - przekażmy na stałe wartość 0,001), a jako funkcję kosztu wykorzystajmy CrossEntropyLoss.\n",
    "\n",
    "Niech zawartość naszej funkcji będzie podobna, jak na poprzednim ćwiczeniu:\n",
    "* Utwórz obiekt klasy ConvNet, a także obiekt zawierający odniesienie do właściwego algorytmu optymalizacji i funkcji kosztu.\n",
    "* Powtarzaj iteracyjnie:\n",
    "    * Przełącz sieć na tryb walidacji, wykonaj *forward pass* na danych walidacyjnych, oblicz wartość kosztu na tych danych i zapisz ją w odpowiedniej zmiennej (pamiętaj o odłączeniu ,,niepotrzebnych'' dla PyTorcha zmiennych metodą `detach()`).\n",
    "    * Przełącz sieć na tryb treningu, wykonaj *forward pass* na danych treningowych, oblicz wartość kosztu na tych danych i zapisz ją w odpowiedniej zmiennej, dokonaj propagacji wstecznej błędu, wykonaj jedną iterację algorytmu optymalizacji, po czym usuń z pamięci obliczone gradienty.\n",
    "    \n",
    "Wyświetlenie zmian kosztu wraz z kolejnymi iteracjami zostało już dla Ciebie napisane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:02:20.786150400Z",
     "start_time": "2023-11-01T18:02:20.695310100Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_cnn(Xtrain, ytrain, Xval, yval, num_classes, kernel_size=3, padding=0, stride=1, lambdA=0.001, if_plot=True):\n",
    "    \"\"\"\n",
    "    Wykonaj trening swojej sieci neuronowej zdefiniowanej w klasie NeuralNet \n",
    "    na zadanych danych wejściowych i z określoną stałą regularyzacji lambdA. \\n\n",
    "    Argumenty: \\n\n",
    "    - Xtrain - dane treningowe (torch tensor, shape = (num_samples * percentage_train, input_channels, sample_size, sample_size) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane testowe (torch tensor, shape = (num_samples * percentage_val, input_channels, sample_size, sample_size) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar), \\n\n",
    "    - kernel_size - wielkość filtra użytego do konwolucji (int, skalar) (opcjonalnie, domyślnie 3), \\n\n",
    "    - padding - wielkość ,,ramki'' dodawanej do danych przed konwolucją (int, skalar) (opcjonalnie, domyślnie 0), \\n\n",
    "    - stride - co ile pikseli ma być robiona konwolucja (int, skalar) (opcjonalnie, domyślnie 1), \\n\n",
    "    - lambdA - stała regularyzacji (float, skalar) (opcjonalnie, domyślnie 0.001), \\n\n",
    "    - if_plot - Boolean, decyduje, czy po treningu wyświetlić krzywe uczenia (opcjonalnie, domyślnie True). \\n\n",
    "    Zwraca: cnn - wytrenowana sieć neuronowa, zdefiniowana w klasie ConvNet.\n",
    "    \"\"\"\n",
    "    cnn = ConvNet( \n",
    "        input_channels = Xtrain.shape[1], \n",
    "        sample_size = Xtrain.shape[2],\n",
    "        output_layer_size=num_classes,\n",
    "        kernel_size=kernel_size, \n",
    "        padding=padding, \n",
    "        stride=stride\n",
    "        ) \n",
    "    cnn = cnn.double() \n",
    "    loss_train_vec = [] \n",
    "    loss_val_vec = []  \n",
    "    # ---------------------------- UZUPEŁNIJ KOD ---------------------------------------\n",
    "    # Utwórz obiekt związany z funkcją kosztu - CrossEntropyLoss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # Utwórz obiekt związany z metodą optymalizacji - Adam\n",
    "    optimizer = torch.optim.Adam(params=cnn.parameters(), lr=0.005, weight_decay=lambdA)  \n",
    "    for i in range(1000):\n",
    "        if if_plot:\n",
    "            # Przełącz sieć w tryb walidacji\n",
    "            cnn.eval()\n",
    "            with torch.no_grad(): \n",
    "                # Wykonaj forward pass na danych walidacyjnych\n",
    "                pred = cnn(Xval) \n",
    "                # Oblicz koszt na tych danych\n",
    "                loss_val = criterion(pred, yval) \n",
    "                # Zapisz koszt w odpowiedniej zmiennej (loss_val_vec)\n",
    "                loss_val_vec.append(loss_val.detach().numpy())\n",
    "        # Przełącz sieć w tryb treningu\n",
    "        cnn.train()\n",
    "        # Wykonaj forward pass na danych treningowych\n",
    "        pred = cnn(Xtrain)\n",
    "        # Oblicz koszt na tych danych\n",
    "        loss_train = criterion(pred, ytrain)\n",
    "        # Wykonaj propagację wsteczną kosztu\n",
    "        loss_train.backward() \n",
    "        # Wykonaj 1 iterację algorytmu optymalizacji\n",
    "        optimizer.step()\n",
    "        # Wyzeruj gradienty\n",
    "        optimizer.zero_grad()\n",
    "        # Zapisz koszt do odpowiedniej zmiennej (loss_train_vec)\n",
    "        loss_train_vec.append(loss_train.detach().numpy())\n",
    "    # ------------------------------------------------------------------------\n",
    "    if if_plot:\n",
    "        print(\"  Zakończono trening sieci.\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_train_vec, color='k')\n",
    "        ax.plot(loss_val_vec, color='r')\n",
    "        ax.set_title(\"Krzywe uczenia\")\n",
    "        ax.set_xlabel(\"Iteracja\")\n",
    "        ax.set_ylabel(\"Koszt\")\n",
    "        ax.legend([\"Koszt na danych treningowych\", \"Koszt na danych walidacyjnych\"])\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, jak zmieniły się predykcje dokonane przez naszą sieć, kiedy czegoś ją nauczyliśmy: powinniśmy widzieć większe zróżnicowanie wyników."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:03:26.680832600Z",
     "start_time": "2023-11-01T18:02:20.701819900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowe predykcje modelu na danych walidacyjnych (po treningu): tensor([[1.1592e-04, 6.4263e-04, 1.6117e-04, 1.7445e-04, 2.3182e-03, 1.0502e-04,\n",
      "         9.8870e-01, 3.1029e-04, 7.8139e-04, 6.6948e-03],\n",
      "        [5.0953e-01, 2.5961e-03, 5.7758e-02, 6.0494e-03, 7.7610e-03, 5.7758e-02,\n",
      "         3.4243e-01, 4.1542e-03, 6.9387e-03, 5.0211e-03],\n",
      "        [1.4118e-03, 1.4118e-03, 6.1305e-05, 1.4118e-03, 3.5347e-05, 9.9354e-01,\n",
      "         1.4118e-03, 7.6379e-05, 3.5438e-04, 2.8670e-04]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "nn = train_cnn(\n",
    "    Xtrain=Xtrain, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes,\n",
    "    if_plot=False)\n",
    "pred = nn(Xval)\n",
    "print(\"Przykładowe predykcje modelu na danych walidacyjnych (po treningu): \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja\n",
    "\n",
    "Kolejnym krokiem jest napisanie funkcji, która analizuje prawdopodobieństwa zwracane przez sieć neuronową i zwraca konkretne numery klas, do których powinny należeć analizowane obrazki - przypomnijmy, że z pomocą `torch.argmax()` należy znaleźć indeks klasy, której sieć przyporządkowała najwyższe prawdopodobieństwo. Uzupełnij więc kod funkcji `pred_cnn()`, która wykona taką operację. <font size=\"2\">Nie zapominaj o argumencie `dim`.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:03:26.686849800Z",
     "start_time": "2023-11-01T18:03:26.678832600Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_cnn(X, cnn):\n",
    "    \"\"\"\n",
    "    Dokonuje ostatecznej predykcji sieci neuronowej (obiektu NeuralNet) - wskazania klasy - dla danych wejściowych X. \\n\n",
    "    Argumenty: \\n\n",
    "    - X - dane wejściowe (torch tensor, shape = (num_samples, num_features) ), \\n\n",
    "    - nn - model sieci neuronowej, obiekt naszej klasy NeuralNet\n",
    "    Zwraca: pred - numer klasy wg klasyfikatora właściwy dla X (numpy array, shape = (num_samples,) ).\n",
    "    \"\"\"\n",
    "    # --------- UZUPEŁNIJ KOD -------------\n",
    "    pred = torch.argmax(cnn(X), dim=1)\n",
    "    # -------------------------------------\n",
    "    return pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy, jak wyglądają nasze predykcje dla danych walidacyjnych, kiedy jednoznacznie wskazujemy, do której klasy przypisać daną próbkę (a nie operujemy na prawdopodobieństwach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:03:26.698874Z",
     "start_time": "2023-11-01T18:03:26.682832300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowe predykcje dla danych walidacyjnych: [0 2 1]\n"
     ]
    }
   ],
   "source": [
    "pred = pred_cnn(Xval, cnn)\n",
    "print(\"Przykładowe predykcje dla danych walidacyjnych: \"+str(pred[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dobór hiperparametrów z wykorzystaniem biblioteki Optuna\n",
    "\n",
    "Przy budowi sieci konwolucyjnych mamy do czynienia z dużą ilością hiperparametrów - wystarczy przypomnieć *kernel_size*, *padding* czy *stride*. Znalezienie idealnego zestawu hiperparametrów ręcznie (tak, jak robiliśmy to podczas poprzedniego ćwiczenia) może być problematyczne. Użyjemy zatem biblioteki o nazwie Optuna, która pomaga nam w optymalizacji wielu hiperparametrów naraz.\n",
    "\n",
    "Zgodnie z tutorialem [TUTAJ](https://optuna.readthedocs.io/en/stable/tutorial/20_recipes/002_multi_objective.html), musimy najpierw napisać funkcję `objective`, która ma określać to, co chcemy optymalizować --- musi wiedzieć, jakie parametry ma dostosowywać, a także znać miarę, według której można ocenić, czy ,,zbliżamy się'' do celu czy też nie. W naszym przypadku, poszukujemy takiego zestawu hiperparametrów *kernel_size*, *padding* czy *stride*, przy których nasza sieć osiąga możliwie najwyższą dokładność na danych walidacyjnych.\n",
    "\n",
    "Uzupełniony kod funkcji `objective` powinien zawierać więc następujące elementy:\n",
    "* Utworzenie obiektów `trial.suggest_int`, definiujących zakres wartości różnych hiperparametrów, które chcemy przebadać (w naszym przypadku, wszystkie szukane wartości są liczbami całkowitymi).\n",
    "* Przeprowadze *forward pass* na danych walidacyjnych:\n",
    "    * utworzenie obiektu klasy ConvNet i wytrenowanie sieci z pewnym (wybranym przez Optunę) zestawem hiperparametrów,\n",
    "    * dokonanie predykcji (funkcja `pred_cnn`) na danych walidacyjnych,\n",
    "* Obliczenie i zwrócenie dokładności predykcji (przypomnij sobie z poprzednich ćwiczeń trick z `np.where`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:03:26.729637700Z",
     "start_time": "2023-11-01T18:03:26.699874400Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, Xtrain, ytrain, Xval, yval, num_classes): \n",
    "    \"\"\"\n",
    "    Funkcja określająca, co ma być optymalizowane przez Optunę\n",
    "    Argumenty:\n",
    "    - trial - wewnętrzny argument Optuny\n",
    "    - Xtrain - dane treningowe (torch tensor, shape = (num_samples * percentage_train, input_channels, sample_size, sample_size) ), \\n\n",
    "    - ytrain - etykiety do danych treningowych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_train, num_classes) ), \\n\n",
    "    - Xval - dane testowe (torch tensor, shape = (num_samples * percentage_val, input_channels, sample_size, sample_size) ), \\n\n",
    "    - yval - etykiety do danych walidacyjnych po one-hot-encodingu\n",
    "        (torch tensor, shape = (num_samples * percentage_val, num_classes) ), \\n\n",
    "    - num_classes - ilość klas, tj. ile różnych wartości pojawia się w etykietach (int, skalar). \\n\n",
    "    Zwraca: accuracy - dokładność sieci na danych walidacyjnych przy badanych hiperparametrach (skalar, float)\n",
    "    \"\"\"\n",
    "    # ------------------------- UZUPEŁNIJ KOD ------------------------------\n",
    "    # Określ wartości hiperparametru kernel_size, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    kernel_sizes = trial.suggest_int(\"kernel_size\", 1, 3, log=False)\n",
    "    # Określ wartości hiperparametru padding, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    paddings = trial.suggest_int(\"padding\", 0, 3, log=False)\n",
    "    # Określ wartości hiperparametru stride, które chcesz przebadać (od 1 do 3, int, bez skali logarytmicznej)\n",
    "    strides = trial.suggest_int(\"stride\", 1, 3, log=False)\n",
    "    # Wytrenuj sieć klasy ConvNet z badanymi hiperparametrami\n",
    "    cnn = train_cnn(\n",
    "          Xtrain=Xtrain, \n",
    "          ytrain=ytrain, \n",
    "          Xval=Xval, \n",
    "          yval=yval, \n",
    "          num_classes=num_classes,\n",
    "          kernel_size=kernel_sizes,\n",
    "          padding=paddings,\n",
    "          stride=strides,\n",
    "          if_plot=False\n",
    "          )\n",
    "    # Dokonaj predykcji na danych walidacyjnych\n",
    "    pred = pred_cnn(Xval, cnn)\n",
    "    # Oblicz dokładność klasyfikacji\n",
    "    accuracy = np.mean(pred==np.where(yval==1)[1]) * 100\n",
    "    # -----------------------------------------------------------------------\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejnym krokiem, po napisaniu funkcji `objective`, jest utworzenie obiektu `study`, który będzie przechowywał wyniki testowania różnych kombinacji wartości hiperparametrów (i dzięki któremu wybierzemy ten optymalny zestaw).\n",
    "* Korzystając z metody `optuna.create_study` (i wskazując w argumencie `direction`, że chcemy maksymalizować optymalizowaną funkcję), utwórz obiekt o nazwie `study`.\n",
    "* Wywołaj na tym obiekcie metodę `optimize` - musisz jej przekazać zdefiniowany wcześniej `objective`, wówczas `study` będzie wiedzieć, co ma optymalizować i w jaki sposób. UWAGA! Musisz zastosować pewien trick opisany [TUTAJ](https://optuna.readthedocs.io/en/stable/faq.html#how-to-define-objective-functions-that-have-own-arguments), aby do funkcji `objective` przekazać własne argumenty $Xtrain$, $ytrain$, $Xval$, $yval$  oraz *num_classes* - proponuję zastosować podejście z lambdą. Jako argument musisz też przekazać ilość prób (losowań zestawu hiperparametrów), które podejmie Optuna (argument `n_trials`) - proponuję w ramach ćwiczeń podać wartość 5, aby czas obliczeń nie był znacząco wydłużony, natomiast w rzeczywistych projektach radzę używać wyższych wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:09:11.208135300Z",
     "start_time": "2023-11-01T18:03:26.702872800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-01 19:03:26,704] A new study created in memory with name: no-name-d1374a8c-324a-4c00-8ee0-c8a48fc282df\n",
      "[I 2023-11-01 19:04:42,971] Trial 0 finished with value: 80.22284122562674 and parameters: {'kernel_size': 3, 'padding': 3, 'stride': 2}. Best is trial 0 with value: 80.22284122562674.\n",
      "[I 2023-11-01 19:07:56,629] Trial 1 finished with value: 73.81615598885793 and parameters: {'kernel_size': 1, 'padding': 2, 'stride': 1}. Best is trial 0 with value: 80.22284122562674.\n",
      "[I 2023-11-01 19:08:16,893] Trial 2 finished with value: 40.389972144846794 and parameters: {'kernel_size': 1, 'padding': 1, 'stride': 2}. Best is trial 0 with value: 80.22284122562674.\n",
      "[I 2023-11-01 19:08:31,909] Trial 3 finished with value: 79.10863509749304 and parameters: {'kernel_size': 3, 'padding': 2, 'stride': 3}. Best is trial 0 with value: 80.22284122562674.\n",
      "[I 2023-11-01 19:09:11,200] Trial 4 finished with value: 29.805013927576603 and parameters: {'kernel_size': 1, 'padding': 3, 'stride': 2}. Best is trial 0 with value: 80.22284122562674.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------ Dobór hiperparametrów ------------------------\n",
    "# ---------------------------- UZUPEŁNIJ KOD ----------------------------\n",
    "# Utwórz obiekt o nazwie study (użyj optuna.create_study, nie zapominaj o argumencie direction)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# Optymalizuj hiperparametry kernel_size, padding i stride - wykonaj optimize() na obiektcie study\n",
    "# (funkcję objective przekaż w postaci wyrażenia lambda)\n",
    "study.optimize(lambda trial: objective(\n",
    "    trial,\n",
    "    Xtrain=Xtrain, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes), \n",
    "    n_trials=5)\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli optymalizacja przebiegła pomyślnie, zobaczmy, jaki zestaw hiperparametrów okazał się najlepszy! Obiekt `study` przechowuje najlepsze wartości w słowniku `best_params` - wystarczy wyszukać po nazwie nadanej hiperparametrowi podczas tworzenia `objective`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:09:11.210140Z",
     "start_time": "2023-11-01T18:09:11.208135300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najwyższa dokładność podczas optymalizacji: 80.22284122562674\n",
      "Najlepszy kernel_size: 3\n",
      "Najlepszy padding: 3\n",
      "Najlepszy stride: 2\n"
     ]
    }
   ],
   "source": [
    "# Wyświetl rezultat optymalizacji\n",
    "print(\"Najwyższa dokładność podczas optymalizacji: \" + str(study.best_value))\n",
    "# ------------------------- UZUPEŁNIJ KOD -------------------------------\n",
    "optimal_kernel_size = study.best_params[\"kernel_size\"]\n",
    "print(\"Najlepszy kernel_size: \" + str(optimal_kernel_size))\n",
    "optimal_padding = study.best_params[\"padding\"]\n",
    "print(\"Najlepszy padding: \" + str(optimal_padding))\n",
    "optimal_stride = study.best_params[\"stride\"]\n",
    "print(\"Najlepszy stride: \" + str(optimal_stride))\n",
    "# -----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mając wybrane wartości hiperparametrów, czas uruchomić właściwy trening naszej konwolucyjnej sieci neuronowej! Uruchom po prostu poniższy kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:10:39.085792700Z",
     "start_time": "2023-11-01T18:09:11.211144600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Zakończono trening sieci.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------- Trening sieci --------------\n",
    "cnn = train_cnn(\n",
    "    Xtrain=Xtrain, \n",
    "    ytrain=ytrain_ohe, \n",
    "    Xval=Xval, \n",
    "    yval=yval_ohe, \n",
    "    num_classes=num_classes,\n",
    "    kernel_size=optimal_kernel_size,\n",
    "    padding=optimal_padding,\n",
    "    stride=optimal_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak zwykle, sprawdź, czy na wykresie krzywych uczenia nie obserwujesz znaczącego *overfittingu* (czy krzywa dla zestawu walidacyjnego nie rośnie przy dalszym spadku krzywej dla zestawu treningowego). Jeśli wszystko jest w porządku, sprawdźmy dokładność naszego modelu także na danych testowych z zestawu MNIST!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:10:39.190094700Z",
     "start_time": "2023-11-01T18:10:39.081583600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność modelu na danych treningowych: 82.93135435992579%\n",
      "Dokładność modelu na danych walidacyjnych: 79.10863509749304%\n",
      "Dokładność modelu na danych testowych: 81.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Predykcja i sprawdzenie działania -------------------\n",
    "pred = pred_cnn(Xtrain, cnn)\n",
    "accuracy = np.mean(pred==ytrain)\n",
    "print(\"Dokładność modelu na danych treningowych: \"+str(accuracy*100)+'%')\n",
    "pred = pred_cnn(Xval, cnn)\n",
    "accuracy = np.mean(pred==yval)\n",
    "print(\"Dokładność modelu na danych walidacyjnych: \"+str(accuracy*100)+'%')\n",
    "pred = pred_cnn(Xtest, cnn)\n",
    "accuracy = np.mean(pred==ytest)\n",
    "print(\"Dokładność modelu na danych testowych: \"+str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Wykorzystanie gotowej architektury - AlexNet\n",
    "\n",
    "Badacze tematyką klasyfikacji obrazów zajmują się od lat. Istnieje wiele gotowych architektur konwolucyjnych sieci neuronowych, które zostały wykrenowane do oceny, co znajduje się na przekazany jej obrazku. Jedną z nich jest AlexNet, wytrenowana na dużym zbiorze zdjęć ImageNet, która rozróżnia 1000 klas obiektów na zdjęciach. AlexNet składa się z pięciu warstw konwolucyjnych, trzech wastw *max pooling*, oraz trzech wastw *fully-connected* (czyli liniowych) na końcu, wewnątrz używa funkcji aktywacji ReLU, a jedynie na warstwie wyjściowej - funkcji Softmax. Tak prezentuje się jej architektura:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<img src='https://i.imgur.com/PWXzmkw.jpg'/>\n",
    "\n",
    "<font size=\"1\">Grafika: hackmd.io / Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, 2012 </font>\n",
    "</div>\n",
    "\n",
    "Jej implementację (wraz z wagami) można pobrać z pomocą PyTorcha. Możemy ją zaimportować do naszego projektu, pobrać etykiety klas używanych przez ImageNet (z repozytorium twórców ImageNet), a następnie dokonać klasyfikacji dowolnego zdjęcia! Musimy jedynie pamiętać, aby odpowiednio zdjęcie przekształcić: musi ono mieć wymiary 3x224x224 (oczywiście jako zdjęcie RGB, stąd 3 kanały), a także być wstępnie znormalizowane. Poniższy fragment kodu, tworzony w oparciu o tutorial [TUTAJ](https://pytorch.org/hub/pytorch_vision_alexnet/) realizuje właśnie wspomniane wyżej zadania:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:10:48.214365900Z",
     "start_time": "2023-11-01T18:10:39.116842300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from jinja2->torch==2.0.1) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Requirement already satisfied: numpy==1.22.3 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (1.22.3)\n",
      "Requirement already satisfied: matplotlib==3.4.2 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from matplotlib==3.4.2) (0.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from matplotlib==3.4.2) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from matplotlib==3.4.2) (1.22.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from matplotlib==3.4.2) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from matplotlib==3.4.2) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from matplotlib==3.4.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.4.2) (1.16.0)\n",
      "Requirement already satisfied: wget==3.2 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement PIL (from versions: none)\n",
      "ERROR: No matching distribution found for PIL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision==0.15.2\n",
      "  Downloading torchvision-0.15.2-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.0/1.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.1/1.2 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 0.7/1.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.2/1.2 MB 7.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torchvision==0.15.2) (1.22.3)\n",
      "Requirement already satisfied: requests in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torchvision==0.15.2) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torchvision==0.15.2) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torchvision==0.15.2) (10.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1->torchvision==0.15.2) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1->torchvision==0.15.2) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1->torchvision==0.15.2) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1->torchvision==0.15.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from torch==2.0.1->torchvision==0.15.2) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from requests->torchvision==0.15.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from requests->torchvision==0.15.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from requests->torchvision==0.15.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from requests->torchvision==0.15.2) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from jinja2->torch==2.0.1->torchvision==0.15.2) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages (from sympy->torch==2.0.1->torchvision==0.15.2) (1.3.0)\n",
      "Installing collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.2a0\n",
      "    Uninstalling torchvision-0.15.2a0:\n",
      "      Successfully uninstalled torchvision-0.15.2a0\n",
      "Successfully installed torchvision-0.15.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Krzysiu/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\Krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Krzysiu\\anaconda3\\envs\\ai_3_8\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Klasyfikacja obrazów z AlexNet -----------------------------\n",
    "# Import niezbędnych bibliotek\n",
    "# ! python -m pip install torch==2.0.1\n",
    "# ! python -m pip install numpy==1.22.3\n",
    "# ! python -m pip install matplotlib==3.4.2\n",
    "# ! python -m pip install wget==3.2\n",
    "# ! python -m pip install PIL\n",
    "# ! python -m pip install torchvision==0.15.2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wget\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Importuj AlexNet - w pełni wytrenowany model\n",
    "alexnet = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "alexnet.eval()\n",
    "# Pobierz nazwy klas, jakie posiada ImageNet\n",
    "if not os.path.exists(\"utils/imagenet_classes.txt\"):\n",
    "    wget.download(\"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\", out=\"utils/imagenet_classes.txt\")\n",
    "with open(\"utils/imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "    \n",
    "# Importuj przykładowe zdjęcie psa\n",
    "if not os.path.exists(\"utils/dog.jpg\"): \n",
    "    wget.download(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", out=\"utils/dog.jpg\")\n",
    "# Przekształć zdjęcie, by AlexNet mógł je przetworzyć\n",
    "input_image = Image.open(\"utils/dog.jpg\")\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czas na Ciebie! Dokonaj klasyfikacji pobranego zdjęcia za pomocą AlexNet. Wykonaj *forward pass* na zdjęciu zapisanym w zmiennej `input_batch`, wywołując `alexnet` jak każdy inny model PyTorcha, wyszukaj klasę z najwyżej ocenionym przez AlexNet prawdopodobieństwem (wykorzystaj znów `torch.argmax`) i w pobranym słowniku etykiet `categories` wyszukaj nazwę odpowiedniej klasy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:10:48.252850200Z",
     "start_time": "2023-11-01T18:10:48.216371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predykcja: Samoyed (0.7244771 pewności)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------ UZUPEŁNIJ KOD --------------------------------\n",
    "# Dokonaj klasyfikacji zdjęcia\n",
    "with torch.no_grad():\n",
    "    output = alexnet(input_batch)\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "pred_class = torch.argmax(probabilities, dim=0)\n",
    "# Odczytaj nazwę klasy\n",
    "pred_category = categories[pred_class]\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nPredykcja: \" + pred_category + \" (\" + str(probabilities[pred_class].numpy()) + \" pewności)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz oczywiście samodzielnie poeksperymentować, podmieniając zdjęcia, których klasyfikacji ma dokonać AlexNet.\n",
    "\n",
    "\n",
    "## 5. Pytania kontrolne\n",
    "1. Opisz bardzo krótko, na czym polega zasada działania konwolucyjnych sieci neuronowych.\n",
    "2. Na co wpływa wartość hiperparametru: *kernel_size* / *padding* / *stride* ?\n",
    "3. Z jakich warstw zazwyczaj składa się konwolucyjna sieć neuronowa?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
